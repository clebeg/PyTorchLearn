{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归\n",
    "PyTorch 深度学习的基本技能已经掌握，从本篇开始进入深度学习模型，任何模型都具备以下基本要素，弄懂一个模型非常简单\n",
    "\n",
    "+ 数据：数据就是输入和已知的输出【监督学习可能没有已知输出】\n",
    "+ 模型：模型就是数学中的一个函数镞，可变化的就是参数，输入到输出的一个映射，一般输出都是一个具体的值，可以是概率和数值\n",
    "+ 参数：一个模型必然包含固定个数或者很多参数\n",
    "+ 损失函数：对任意一个模型，我们总能找到一个办法衡量它的好坏，这个办法就是损失函数\n",
    "+ 优化方法：对一个固定的损失函数，我们通过优化算法，就能求出模型的参数\n",
    "\n",
    "\n",
    "上面每一个概念在 PyTorch 中都有一个对应方式    \n",
    "以后我们统一 y 表示输出，x1，x2，..... 表示单个输入变量，X 表示输入向量，一个样本\n",
    "\n",
    "## 线性回归模型\n",
    "线性回归模型怎么对应上面的几个基本要素呢\n",
    "+ 数据：根据问题来的，比如预测某个地区的房价，必然会收集很多房子的特征：面积、楼龄、周边商超数量、卧室数量等，还会收集它现在的价格，这个就是数据\n",
    "+ 模型：线性回归就是规定模型必须是：p = b + a1*x1 + a2*x2 + an*xm, b 是 bias\n",
    "+ 参数：b a1 a2 am 就是参数\n",
    "+ 损失函数：z = sum(sum((y-p)*(y-p))/m)/n\n",
    "+ 优化方法：梯度下降等\n",
    "\n",
    "当模型和损失函数形式较为简单时，上面的误差最小化问题的解可以直接用公式表达出来。这类解叫作解析解（analytical solution）。本节使用的线性回归和平方误差刚好属于这个范畴。然而，大多数深度学习模型并没有解析解，只能通过优化算法有限次迭代模型参数来尽可能降低损失函数的值。这类解叫作数值解（numerical solution）。\n",
    "\n",
    "## 优化方法\n",
    "在求数值解的优化算法中，小批量随机梯度下降（mini-batch stochastic gradient descent）在深度学习中被广泛使用。它的算法很简单：先选取一组模型参数的初始值，如随机选取；接下来对参数进行多次迭代，使每次迭代都可能降低损失函数的值。在每次迭代中，先随机均匀采样一个由固定数目训练数据样本所组成的小批量（mini-batch）[Math Processing Error]B，然后求小批量中数据样本的平均损失有关模型参数的导数（梯度），最后用此结果与预先设定的一个正数的乘积作为模型参数在本次迭代的减小量。\n",
    "\n",
    "下面我们来用 PyTorch 来构建整个线性回归模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}